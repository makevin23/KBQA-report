% Encoding: UTF-8

@article{DBLP:journals/corr/abs-2103-06752,
  author    = {Daniel Vollmers and
               Rricha Jalota and
               Diego Moussallem and
               Hardik Topiwala and
               Axel{-}Cyrille Ngonga Ngomo and
               Ricardo Usbeck},
  title     = {Knowledge Graph Question Answering using Graph-Pattern Isomorphism},
  journal   = {CoRR},
  volume    = {abs/2103.06752},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.06752},
  eprinttype = {arXiv},
  eprint    = {2103.06752},
  timestamp = {Tue, 16 Mar 2021 11:26:59 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-06752.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{soru-marx-nampi2018,
    author = "Tommaso Soru and Edgard Marx and Andr\'e Valdestilhas and Diego Esteves and Diego Moussallem and Gustavo Publio",
    title = "Neural Machine Translation for Query Construction and Composition",
    year = "2018",
    journal = "ICML Workshop on Neural Abstract Machines \& Program Induction (NAMPI v2)",
    url = "https://arxiv.org/abs/1806.10478",
}

@inproceedings{gerbil,
author = {Cornolti, Marco and Ferragina, Paolo and Ciaramita, Massimiliano},
title = {A Framework for Benchmarking Entity-Annotation Systems},
year = {2013},
isbn = {9781450320351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488388.2488411},
doi = {10.1145/2488388.2488411},
abstract = {In this paper we design and implement a benchmarking framework for fair and exhaustive comparison of entity-annotation systems. The framework is based upon the definition of a set of problems related to the entity-annotation task, a set of measures to evaluate systems performance, and a systematic comparative evaluation involving all publicly available datasets, containing texts of various types such as news, tweets and Web pages. Our framework is easily-extensible with novel entity annotators, datasets and evaluation measures for comparing systems, and it has been released to the public as open source. We use this framework to perform the first extensive comparison among all available entity annotators over all available datasets, and draw many interesting conclusions upon their efficiency and effectiveness. We also draw conclusions between academic versus commercial annotators.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {249â€“260},
numpages = {12},
keywords = {wikipedia},
location = {Rio de Janeiro, Brazil},
series = {WWW '13}
}

@inproceedings{isem2013daiber,
  title = {Improving Efficiency and Accuracy in Multilingual Entity Extraction},
  author = {Joachim Daiber and Max Jakob and Chris Hokamp and Pablo N. Mendes},
  year = {2013},
  booktitle = {Proceedings of the 9th International Conference on Semantic Systems (I-Semantics)}
}

@Comment{jabref-meta: databaseType:bibtex;}
