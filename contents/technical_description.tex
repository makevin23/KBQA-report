% Technical description of the method to solve the task (~1 - 2 page)

\section{Approach Description}

% NSpM
Our basis approach is the Neural SPARQL Machine (NSpM)\cite{soru-marx-nampi2018},
which considers SPARQL query as another natural language and employ machine translation techniques. 
NSpM consists of three main components: 
Generator, Learner and Interpreter. 
Generator generates a training set
by fulling entities from knowledge graph into question and query templates with placeholders. 

Following is an example of template and generated questions and queries:

\begin{verbatim}
    Where is <A> located in?; 
                    SELECT ?x { <A> dbo:location ?x }
\end{verbatim}

\begin{verbatim}
    Where is London located in?; 
                    SELECT ?x { dbr:London dbo:location ?x }
    Where is the Colosseum located in?; 
                    SELECT ?x { :Colosseum :location ?x }
    Where is Mount Everest located in?; 
                    SELECT ?x { :Mount_Everest :location ?x }
\end{verbatim}

Learner is a deep neural network based translator, 
which translates a sequence of tokens in natural language
into a sequence which encodes a SPARQL query after training.
Interpreter uses the learned model to predict a SPARQL query for received question.

There are two drawbacks in this original NSpM.
Since training data is generated using templates, 
the number of entities are severely restricted,
which leads to a bad performance in evaluation.
Or the training set has to be very large
that makes it hard to train with. 
Besides, there is no template for QALD 8 and 9 training set,
which make comparisons difficult. 
On the other hand, 
learner consists only of a one-layer encoder and a one-layer decoder.
The performance will be greatly improved using other neural network model.
To improve NSpM, we used DBpedia Spotlight and Pegasus model. 

% DBpedia spotlight
DBpedia Spotlight \cite{isem2013daiber} is a tool for automatic annotating and entity linking, 
which performs entity extraction including entity detection and name resolution. 
First, we integrated DBpedia Spotlight into the interpreter to detect entities. 
We abandoned generator and trained with templates directly. 
Then in the prediction phase, 
when interpreter receives a question, 
it detects entities in the question using DBpedia Spotlight and replaces them with placeholders.
Interpreter translates this modified question into a SPARQL query with placeholders
and restores entities again. 
Integration of DBpedia Spotlight in interpreter decreases the size of training set
and therefore the training effort is reduced. 
However, the performance is better,
since it uses the entire knowledge graph while prediction
and learner only needs to focus on learning predicates in SPARQL query. 

% Pegasus

% Gerbil
Gerbil \cite{gerbil} is a web-based platform for comparison of QA system. 
User can upload test set and add a QA system via URI or upload a JSON file with answers in QALD-JSON format. 
We focused on QALD 8 and 9 for evaluation. 
At the beginning, we generated a JSON file with answers and uploaded it to gerbil. 
Later once we deployed our QA system on VM, we added our system via URI every time. 

% ConvS2S