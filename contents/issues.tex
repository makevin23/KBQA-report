% A summary of issues (~0.5 page)

\section{Issues}

During this project group,
I have met many issues, 
but with the help of our teammates, 
they were solved quickly.

% VM
At first, I did not know what to do with our virtual machine. 
I asked my teammates then figured out how to deploy our software on it. 

% gerbil
In our evaluation at beginning, 
we must create our data set in qald format with answer
and upload it to gerbil,
since the system was not deployed on VM at that time. 
We created a script to do it automatically. 

% dataset
Inspired by templates and generator in the original NSpM model,
we used templates, questions and queries with placeholders, for training directly.
For training on qald 8 and 9, 
we did not have a data set suitable for our approach. 
Thus, we implemented a script to replace entities in qald 8 and 9 with placeholders
and convert to the format we need. 
In order to include more predicates in our data set, 
we also checked classes in DBpedia 
and wrote questions and queries on our own. 

% GPU cuda
While training our model on felis Server, 
I encountered some issues with incompatible cuda and driver version. 
This was fixed quickly after some research. 

% ConvS2S
At the beginning of the second semester,
we found Convolutional Sequence-to-Sequence model (ConvS2S),
which is written in tensorflow version 1. 
There is a big difference between Tensorflow version 1 and 2,
we have spent a lot of time to rewrite it in tensorflow two
and add additional features that we want.
However, after the implementation we trained ConvS2S with our questions and queries,
it could not predict any query. 
We tried a lot to fix this model, 
but it did not work in the end
and we switch to Pegasus model. 

% pretrain
At the end of project group, 
we wanted to pre-train on LC-QALD and fine-tune on qald 8 and 9,
which could not be done directly. 
After checking parameters in Pegasus model, 
we found a way to do it. 